{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries & define constants\n",
    "Import the needed libraries and define the constant of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discriminate the runtime used:\n",
    "- 0: Local\n",
    "- 1: Colab\n",
    "- 2: Kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RUNTIME = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from math import sqrt, ceil\n",
    "import os\n",
    "#from os import listdir\n",
    "#import shutil\n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "from mlxtend.plotting import plot_confusion_matrix # Plot confusion matrix\n",
    "#import seaborn as sns # Plotting\n",
    "from sklearn.metrics import confusion_matrix, classification_report # Metrics of the architecture\n",
    "import numpy as np # Scintific computing\n",
    "import tensorflow as tf # Platform for Machine Learning\n",
    "# Keras: Neural Networks API\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D #, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras import applications, Model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "DATASET_PATH = \"../res/dataset/\" # Dataset directory (containing train/val/test folders)\n",
    "MODEL_PARAM_DIR = \"../res/model_param/\" # Directory where to load or save the model's parameter (model or weight)\n",
    "# LOAD = True when the task is to evaluate the model\n",
    "# LOAD = False when the task is to train the model\n",
    "LOAD = True\n",
    "# LOAD_MODEL = True when the model has to be loaded\n",
    "# LOAD_MODEL = False when the weights have to be loaded\n",
    "LOAD_MODEL = True\n",
    "# SAVE_BEST = True when the best weights have to be saved; False otherwise\n",
    "SAVE_BEST = True\n",
    "\n",
    "if RUNTIME == 1:\n",
    "    DATASET_PATH = \"/content/ds_unzipped/chest_xray/chest_xray/\" # Set the path to the unzipped dataset\n",
    "    # Save the parameters on the Google Drive filesystem\n",
    "    MODEL_PARAM_DIR = \"/content/drive/My Drive/Colab Notebooks/Project/res/weights/\"\n",
    "    LOAD = False # Main duty of Colab: training the model\n",
    "elif RUNTIME == 2:\n",
    "    DATASET_PATH = \"../input/chest-xray-pneumonia/chest_xray/chest_xray/\" # Set the path to the unzipped dataset\n",
    "    MODEL_PARAM_DIR = \"\" # Save the parameters in the current folder\n",
    "    LOAD = False # Main duty of Kaggle: training the model\n",
    "\n",
    "# Dictionary containing the different paths for train/val/test\n",
    "PATHS = {\"train\": DATASET_PATH+\"train/\", \"val\": DATASET_PATH+\"val/\", \"test\": DATASET_PATH+\"test/\"}\n",
    "#path_labels = {\"normal\": \"NORMAL/\", \"pneumonia\": \"PNEUMONIA/\", \"bacteria\": \"BACTERIA/\", \"virus\": \"VIRUS/\", }\n",
    "\n",
    "# List containing the labels of the dataset (e.g. [\"normal\", \"pneuomonia\"])\n",
    "LABELS = [item.lower() for item in os.listdir(PATHS[\"train\"])]\n",
    "\n",
    "SEED = 42 # Seed for Random Number Generation\n",
    "\n",
    "SHUFFLE = False # The generators above returns the same batches: needed for a correct confusion matrix\n",
    "# Even if the dataset is gray-level, we replicate the image over the 3 RGB channels: needed for pre-trained networks:\n",
    "# those are trained on RGB images (see the input shape above)\n",
    "COLOR_MODE = 'rgb'\n",
    "# Only 2 classes (normal/pneumonia), binary task (needed for the generator)\n",
    "CLASS_MODE = \"binary\" #or 'categorical'\n",
    "# Parameters for the ImageDataGenerator. For more information, see: https://keras.io/preprocessing/image/\n",
    "RESCALE = 1./255\n",
    "ROTATION_RANGE = 15\n",
    "WIDTH_SHIFT_RANGE = 0.2\n",
    "HEIGHT_SHIFT_RANGE = 0.2\n",
    "SHEAR_RANGE = 0.15\n",
    "ZOOM_RANGE=0.2\n",
    "HORIZONTAL_FLIP = True\n",
    "FILL_MODE = \"nearest\"\n",
    "INPUT_SHAPE = (256, 256, 1) # Input shape of the neural network\n",
    "# Depending on the backend, the channel can be the first or the last parameter of a tuple\n",
    "if tf.keras.backend.image_data_format() == 'channels_first': \n",
    "    INPUT_SHAPE = (INPUT_SHAPE[-1], INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "# Input shape representing the replicated gray-level images (1 channel) on the 3 RGB channels for pre-trained networks:\n",
    "# from (256, 256, 1) to (256, 256, 3)\n",
    "INPUT_SHAPE3 = INPUT_SHAPE[0:2]+(3,)\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    INPUT_SHAPE3 = (INPUT_SHAPE3[-1], INPUT_SHAPE3[0], INPUT_SHAPE3[1])\n",
    "\n",
    "# Parameters of the Neural Network\n",
    "POOL_SIZE = (2,2) # Pool size of the Convolutional Neural Network \"pooling layer\"\n",
    "KERNEL_SIZE = (3,3) # Kernel size of the Convolutional Neural Network\n",
    "ACTIVATION_HIDDEN_LAYERS = 'relu' # Activation function for the hidden layers\n",
    "ACTIVATION_OUTPUT_LAYER = 'sigmoid' #or 'softmax' # Activation function of the output layer\n",
    "DROPOUT = 0.5 # Dropout value to reduce overfitting\n",
    "# Output neuron for the binary task: predicting the probability of the image being \n",
    "# \"normal\" (if the probability is smaller or equal than a threshold (<= 0.5))\n",
    "# \"pneumonia\" (if the probability is greater than a threshold (> 0.5))\n",
    "OUTPUT_NEURONS = 1 #or 3\n",
    "\n",
    "# Parameter for compuling the model\n",
    "LOSS = 'binary_crossentropy' #or 'categorical_crossentropy' # Loss function\n",
    "OPTIMIZER = 'adam' # Optimizer of the gradient\n",
    "METRICS = ['accuracy'] # Metrics used for evaluating the training\n",
    "\n",
    "BATCH_SIZE = 16 # Batch size used for training/validating/testing\n",
    "EPOCHS = 50 # Number of epochs to train the Neural Network\n",
    "\n",
    "# Weights used for pre-trained network: imagenet dataset\n",
    "WEIGHTS = \"imagenet\"\n",
    "\n",
    "# Number of unfreezed layers of the VGG16 pre-trained network\n",
    "UNFREEZED = 11 # 11 for last 2 blocks, 15 for last block\n",
    "# Learning rate for Stocastic Gradient Descent: little so to avoid damaging the low level weights (the unfreezed ones)\n",
    "LR = 1e-4 \n",
    "MOMENTUM = 0.9 # SGD momentum\n",
    "REGULARIZER = l1(1e-3) # Regularization to improve the generalization capabilities of the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and set the generators\n",
    "Load the images, setting up the generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Set the seed\n",
    "np.random.seed(SEED)\n",
    "if RUNTIME == 1: # Compatibility (tensorflow 2.0 and 1.5 (on Colab)) for setting the random seed\n",
    "    tf.set_random_seed(SEED)\n",
    "else:   \n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Train and validtion ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=RESCALE, shear_range=SHEAR_RANGE, zoom_range=ZOOM_RANGE, \n",
    "                                   rotation_range=ROTATION_RANGE)\n",
    "#train_datagen = ImageDataGenerator(rescale=RESCALE, rotation_range=ROTATION_RANGE, width_shift_range=WIDTH_SHIFT_RANGE, \n",
    "# height_shift_range=HEIGHT_SHIFT_RANGE, horizontal_flip=HORIZONTAL_FLIP, shear_range=SHEAR_RANGE, fill_mode=FILL_MODE)\n",
    "# Test ImageDataGenerator: only rescale is done\n",
    "test_datagen = ImageDataGenerator(rescale=RESCALE)\n",
    "\n",
    "# Setup the 3 generators, reading from the corresponding directories\n",
    "train_generator = train_datagen.flow_from_directory(PATHS[\"train\"], target_size=INPUT_SHAPE3[0:2], \n",
    "                                                    batch_size=BATCH_SIZE, color_mode=COLOR_MODE, \n",
    "                                                    class_mode=CLASS_MODE, seed=SEED, shuffle=SHUFFLE)\n",
    "val_generator = test_datagen.flow_from_directory(PATHS[\"val\"], target_size=INPUT_SHAPE3[0:2], \n",
    "                                                 batch_size=BATCH_SIZE, color_mode=COLOR_MODE, \n",
    "                                                 class_mode=CLASS_MODE, seed=SEED, shuffle=SHUFFLE)\n",
    "test_generator = test_datagen.flow_from_directory(PATHS[\"test\"], target_size=INPUT_SHAPE3[0:2], \n",
    "                                                  batch_size=BATCH_SIZE, color_mode=COLOR_MODE, \n",
    "                                                  class_mode=CLASS_MODE, seed=SEED, shuffle=SHUFFLE)\n",
    "\n",
    "# Number of images in each folder\n",
    "image_count = {\"train\": len(train_generator.filenames), \"val\": len(val_generator.filenames), \n",
    "               \"test\": len(test_generator.filenames)}\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = {\"train\": np.ceil(image_count[\"train\"]/BATCH_SIZE), \"val\": np.ceil(image_count[\"val\"]/BATCH_SIZE), \n",
    "                   \"test\": np.ceil(image_count[\"test\"]/BATCH_SIZE)}\n",
    "# Number of elements for each class in the train dataset: needed to show the number of samples for each class\n",
    "num_elem_for_class_train = {\"normal\": len(os.listdir(PATHS[\"train\"]+\"/NORMAL\")), \n",
    "                            \"pneumonia\": len(os.listdir(PATHS[\"train\"]+\"/PNEUMONIA\"))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show batch\n",
    "Function which shows the images of a particular batch, with the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Shows the images of a particular batch, with the corresponding label\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_batch : array\n",
    "        Array representing the batch of images\n",
    "    label_batch : array\n",
    "        Array representing the labels of a batch of images\n",
    "    size : int\n",
    "        Size of the batch\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    void\n",
    "\"\"\"\n",
    "def show_batch(image_batch, label_batch, size):\n",
    "    figsize = (10,10)\n",
    "    cmap = \"gray\"\n",
    "    axis = \"off\"\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    rows_cols = ceil(sqrt(size))\n",
    "  \n",
    "    for n in range(size):\n",
    "        plt.subplot(rows_cols,rows_cols,n+1)\n",
    "        plt.imshow(image_batch[n][:,:,0], cmap=cmap)\n",
    "        #plt.title(LABELS[(label_batch[n]==1).tolist().index(True)]) # for multiclass\n",
    "        plt.title(LABELS[0].capitalize() if label_batch[n] == 1 else LABELS[1].capitalize())\n",
    "        plt.axis(axis)\n",
    "\n",
    "# Return the batch from a generator\n",
    "image_batch, label_batch = next(train_generator)\n",
    "show_batch(image_batch, label_batch, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learning\n",
    "Function to plot the loss and the accuracy of train and validation sets over the different epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function to plot the loss and the accuracy of train and validation sets over the different epochs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : History\n",
    "        History object. Its History.history attribute is a record of training loss values and metrics values \n",
    "        at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    void\n",
    "\"\"\"\n",
    "def plot_learning(name, history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    # Plot training and validation accuracy per epoch\n",
    "    plt.plot(epochs, acc)\n",
    "    plt.plot(epochs, val_acc)\n",
    "    plt.title('Traini and validation accuracy')\n",
    "    plt.savefig(MODEL_PARAM_DIR+\"acc_\"+name+'.png') # Move in a folder for plots\n",
    "    plt.figure()\n",
    "    \n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.title('Train and validation loss')\n",
    "    plt.savefig(MODEL_PARAM_DIR+\"loss_\"+name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save function\n",
    "Function with the duty of loading or saving (after training) the model. <br><br>\n",
    "In the function are defined several callbacks (ReduceLRONPlateau, EarlyStopping, ModelCheckpoint) and the possibility\n",
    "to load the weights or the model or save the model after the training. <br>\n",
    "At the end, a plot of the training and validation accuracy/loss is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function with the duty of loading or saving (after training) the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Name of the model\n",
    "    model : Model\n",
    "        Model (Keras.Sequential) of the Convolutional Neural Network\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : Model\n",
    "        Compiled model after loading or saving\n",
    "\"\"\"\n",
    "def load_save(name, model):\n",
    "    callbacks = []\n",
    "    reduce_learning_rate = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, cooldown=2, min_lr=1e-5,verbose=1)\n",
    "    callbacks.append(reduce_learning_rate)\n",
    "    \n",
    "    es = EarlyStopping(patience=5)\n",
    "    #callbacks.append(es)\n",
    "    \n",
    "    if SAVE_BEST:\n",
    "        filepath = MODEL_PARAM_DIR+\"model_\"+NAME+\"-{epoch:02d}.h5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "        callbacks.append(checkpoint)\n",
    "        \n",
    "    if LOAD:\n",
    "        if LOAD_MODEL:    \n",
    "            model = load_model(MODEL_PARAM_DIR+\"model_\"+name+'.h5')\n",
    "        else:\n",
    "            model.load_weights(MODEL_PARAM_DIR+\"weights_\"+name+'.h5')\n",
    "            \n",
    "        model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    else:\n",
    "        model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "        history = model.fit_generator(train_generator, validation_data=val_generator, epochs=EPOCHS, \n",
    "                steps_per_epoch=steps_per_epoch[\"train\"], validation_steps=steps_per_epoch[\"val\"], callbacks=callbacks)\n",
    "       \n",
    "        plot_learning(name, history)\n",
    "        \n",
    "        model.save(MODEL_PARAM_DIR+\"model_\"+name+'.h5')\n",
    "        model.save_weights(MODEL_PARAM_DIR+\"weights_\"+name+'.h5')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "This section is the core part of the project. Here it is defined the model of several CNN architectures:\n",
    "- A simple Convolutional Neural Network\n",
    "- Transfer learning with a pre-trained network\n",
    "- Transfer learning with a pre-trained network and fine-tuning of top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Simple CNN\n",
    "The following architecture is composed as follows:\n",
    "(Conv2D, MaxPooling2D) (x 3) -> Flatten -> Dense -> Dropout -> Dense <br><br>\n",
    "Below some characteristics about the hyper-parameters (same of the constants defined above):\n",
    "- Activation function\n",
    "    - Hidden layers: ReLU\n",
    "    - Output layer: Sigmoid\n",
    "- Units\n",
    "    - Hidden layers: 32/64\n",
    "    - Output layer: 1\n",
    "- Kernel size: (3, 3)\n",
    "- Pool size: (2, 2)\n",
    "- Input shape: (256, 256, 3)\n",
    "- Dropout rate: 0.5 \n",
    "- Regularizer: l1 with learning rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"simple_regularizer\" # Model name for load_save function\n",
    "\n",
    "model = Sequential() # Sequential model\n",
    "\n",
    "# Architecture of the CNN\n",
    "model.add(Conv2D(32, KERNEL_SIZE, input_shape=INPUT_SHAPE3))\n",
    "model.add(Activation(ACTIVATION_HIDDEN_LAYERS))\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "\n",
    "model.add(Conv2D(32, KERNEL_SIZE))\n",
    "model.add(Activation(ACTIVATION_HIDDEN_LAYERS))\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "\n",
    "model.add(Conv2D(64, KERNEL_SIZE))\n",
    "model.add(Activation(ACTIVATION_HIDDEN_LAYERS))\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
    "\n",
    "model.add(Flatten()) # Converts 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64, activity_regularizer=REGULARIZER))\n",
    "#model.add(Dense(64),\n",
    "model.add(Activation(ACTIVATION_HIDDEN_LAYERS))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(OUTPUT_NEURONS))\n",
    "model.add(Activation(ACTIVATION_OUTPUT_LAYER))\n",
    "\n",
    "# Load or save the model\n",
    "model = load_save(NAME, model)\n",
    "\n",
    "# Output the validation and testing loss/accuracy\n",
    "val_score = model.evaluate_generator(val_generator, steps_per_epoch[\"val\"])\n",
    "test_score = model.evaluate_generator(test_generator, steps_per_epoch[\"test\"])\n",
    "#predict = model.predict_generator(test_generator, steps=steps_per_epoch[\"test\"])\n",
    "\n",
    "print(\"Validation loss: {0:.4f}, validation accuracy: {0:.4f}\".format(val_score[0], val_score[1]))\n",
    "print(\"Test loss: {0:.4f}, test accuracy: {0:.4f}\".format(test_score[0], test_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer learning with pre-trained network (VGG16)\n",
    "To improve the overall performances of the network, it is used a technique called \"transfer learning\", \n",
    "that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. \n",
    "<br><br> The architecture is the VGG16, trained on the \"imagenet\" dataset \n",
    "(for more information, see: https://neurohive.io/en/popular-networks/vgg16/). <br>\n",
    "To this model, it is appended a basic CNN, that learns the features of the current dataset. <br>\n",
    "The layers of the VGG16 architecture are freezed, so to avoid damaging the weights learned.\n",
    "Then, the top layers of the VGG16 architecture are unfreezed, for fine-tuning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic architecture\n",
    "The basic CNN architecture is composed as follows:\n",
    "Flatten -> Dense -> Dropout -> Dense <br><br>\n",
    "Below some characteristics about the hyper-parameters (same of the constants defined above):\n",
    "- Activation function\n",
    "    - Hidden layers: ReLU\n",
    "    - Output layer: Sigmoid\n",
    "- Units\n",
    "    - Hidden layers: 512\n",
    "    - Output layer: 1\n",
    "- Input shape: (256, 256, 3)\n",
    "- Dropout rate: 0.5 \n",
    "- Regularizer: l1 with learning rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"vgg16_freeze2_before_regularizer\" # Model name for load_save function\n",
    "\n",
    "OPTIMIZER = SGD(lr=LR, momentum=MOMENTUM) # Optimizer\n",
    "\n",
    "# Load the VGG16 network without including top layers\n",
    "base_model = applications.VGG16(weights=WEIGHTS, include_top=False, input_shape=INPUT_SHAPE3)\n",
    " \n",
    "# Define the basic CNN\n",
    "headModel = base_model.output\n",
    "headModel = Flatten()(headModel)\n",
    "headModel = Dense(512, activation=ACTIVATION_HIDDEN_LAYERS, activity_regularizer=REGULARIZER)(headModel)\n",
    "#headModel = Dense(512, activation=ACTIVATION_HIDDEN_LAYERS)(headModel)\n",
    "headModel = Dropout(DROPOUT)(headModel)\n",
    "headModel = Dense(OUTPUT_NEURONS, activation=ACTIVATION_OUTPUT_LAYER)(headModel)\n",
    " \n",
    "# Append the basic CNN to the VGG16 architecture\n",
    "model = Model(inputs=base_model.input, outputs=headModel)\n",
    "\n",
    "# Freeze the VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# Load or save the model\n",
    "model = load_save(NAME, model)\n",
    "\n",
    "# Output the validation and testing loss/accuracy\n",
    "val_score = model.evaluate_generator(val_generator, steps_per_epoch[\"val\"])\n",
    "test_score = model.evaluate_generator(test_generator, steps_per_epoch[\"test\"])\n",
    "\n",
    "print(\"Validation loss: {0:.4f}, validation accuracy: {0:.4f}\".format(val_score[0], val_score[1]))\n",
    "print(\"Test loss: {0:.4f}, test accuracy: {0:.4f}\".format(test_score[0], test_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning of top layers\n",
    "To improve the performances, the top layers of the VGG16 architecture are unfreezed. <br>\n",
    "Fine-tuning should be done with a very slow learning rate, and typically with the SGD optimizer rather than an \n",
    "adaptative learning rate optimizer such as RMSProp. This is to make sure that the magnitude of the updates stays \n",
    "very small, so as not to wreck the previously learned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model name for load_save function\n",
    "NAME = \"vgg16_freeze2_after_regularizer\"\n",
    "\n",
    "# Reset the data generators\n",
    "train_generator.reset()\n",
    "val_generator.reset()\n",
    "test_generator.reset()\n",
    " \n",
    "# Unfreeze the top layers, allowing the fine-tuning of these\n",
    "for layer in base_model.layers[UNFREEZED:]:\n",
    "\tlayer.trainable = True\n",
    "\n",
    "# Load or save the model\n",
    "model = load_save(NAME, model)\n",
    "\n",
    "# Output the validation and testing loss/accuracy\n",
    "val_score = model.evaluate_generator(val_generator, steps_per_epoch[\"val\"])\n",
    "test_score = model.evaluate_generator(test_generator, steps_per_epoch[\"test\"])\n",
    "\n",
    "print(\"Validation loss: {0:.4f}, validation accuracy: {0:.4f}\".format(val_score[0], val_score[1]))\n",
    "print(\"Test loss: {0:.4f}, test accuracy: {0:.4f}\".format(test_score[0], test_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "Plot the confusion matrix and the classification report of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the true and predicted labels\n",
    "true = test_generator.classes\n",
    "pred = model.predict_generator(test_generator, steps=steps_per_epoch[\"test\"])\n",
    "# Set a threshold\n",
    "y_pred = pred > 0.5 #or y_pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(true, y_pred)\n",
    "\n",
    "# Obtain the true negativesm false positives, ...\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn/(tn+fp)*100\n",
    "#print(specificity)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#sns.set_style('whitegrid')\n",
    "#sns.barplot(x=['Normal','Pneumonia'],y=[num_elem_for_class_train[\"normal\"], num_elem_for_class_train[\"pneumonia\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test some images\n",
    "Test the architecture with some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load an image and make it suitable for predicting, finally rescale it\n",
    "img = image.load_img('yes.jpeg', target_size=(256, 256))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255.\n",
    "image = np.vstack([x])\n",
    "\n",
    "# Predict the class of the image\n",
    "classes = model.predict(image)\n",
    "print(\"Probability: {}, class (False for class 0 (normal), True for class 1 (pneumonia)): {}\".format(classes[0], \n",
    "                                                                                                     classes[0]>0.5))\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(x[0])                           \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}